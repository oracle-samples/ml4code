---

title: Literature
weight: 1
url: papers
bookCollapseSection: true
---
# Papers
This section contains summaries of selected research papers. The summaries are maintained by various contributors.

|Title|Author|Year|Link|
|-----|-----|----|----| 
|[Structcoder: Structure-aware transformer for code generation]({{< ref "docs/01_papers/02_pretrain/07_structcoder.md" >}} )| Tipirneni et al.| 2024 |[ACM](https://dl.acm.org/doi/pdf/10.1145/3636430)|
|Learning and Evaluating Contextual Embedding of Source Code|Kanade et al.| 2019 |[arXiv](https://arxiv.org/pdf/2001.00059.pdf)|
|Fuzz4All: Universal Fuzzing with Large Language Models | Xia et al. | 2024 |[arXiv](https://arxiv.org/pdf/2308.04748.pdf) |
|Large Language Models are Zero-Shot Fuzzers: Fuzzing Deep-Learning Libraries via Large Language Models | Deng et al. | 2023 | [arXiv](https://arxiv.org/abs/2212.14834)|
|Large Language Models for Code: Security Hardening and Adversarial Testing | He et al. | 2024 |[arXiv](https://arxiv.org/abs/2302.05319)|
|SymLM: Predicting Function Names in Stripped Binaries via Context-Sensitive Execution-Aware Code Embeddings| Jin et al. | 2022 | [ACM](https://dl.acm.org/doi/pdf/10.1145/3548606.3560612) | 
|TRACED: Execution-aware Pre-training for Source Code|Ding et al.|2024|[arXiv](https://arxiv.org/pdf/2306.07487.pdf)|
|CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding and Generation|Lu et al.|2021|[arXiv](https://arxiv.org/pdf/2102.04664.pdf)|
|RepairLLaMA: Efficient Representations and Fine-Tuned Adapters for Program Repair|Silva et al|2023|[arXiv](https://arxiv.org/pdf/2312.15698)|
|Grace: Language Models Meet Code Edits|Gupta et al.|2023|[arXiv](https://arxiv.org/pdf/2305.14129.pdf)|
|SkipAnalyzer: A Tool for Static Code Analysis with Large Language Models|Mohajer et al|2023|[arXiv](https://arxiv.org/pdf/2310.18532)|
|Studying LLM Performance on Closed- and Open-source Data|Ahmed et al.|2024|[arXiv](https://arxiv.org/pdf/2402.15100.pdf)|
|Rewriting the Code: A Simple Method for Large Language Model Augmented Code Search|Li et al.|2024|[arXiv](https://arxiv.org/pdf/2401.04514.pdf)|
|Automatically Testing Functional Properties of Code Translation Models|Eniser et al.|2023|[arXiv](https://arxiv.org/pdf/2309.12813.pdf)|
|Think Outside the Code: Brainstorming Boosts Large Language Models in Code Generation|Li et al|2023|[arXiv](https://arxiv.org/pdf/2305.10679.pdf9)|
|Rethinking Negative Pairs in Code Search|Li et al.|2023|[arXiv](https://arxiv.org/pdf/2310.08069.pdf)|
|Supersonic: Learning to Generate Source Code Optimizations in C/C++|Chen et al|2023|[arXiv](https://arxiv.org/pdf/2309.14846)|
|Guiding Language Models of Code With Global Context using Monitors|Agarwal et al|2023|[arXiv](https://arxiv.org/pdf/2306.10763.pdf)|
|OctoPack: Instruction Tuning Code Large Language Models|Muennighoff et al|2023|[arXiv](https://arxiv.org/pdf/2308.07124.pdf)|
|The Hitchhiker's Guide to Program Analysis: A Journey with Large Language Models|Li et al|2023|[arXiv](https://arxiv.org/pdf/2308.00245)|
|LongCoder: A Long-Range Pre-trained Language Model for Code Completion|Guo et al.|2023|[arXiv](https://arxiv.org/pdf/2306.14893.pdf)|
|LLM4Decompile: Decompiling Binary Code with Large Language Models|Tan et al|2024|[arXiv](https://arxiv.org/pdf/2403.05286.pdf)|
|A Survey of Source Code Representations for Machine Learning-Based Cybersecurity Tasks|Casey et al|2024|[arXiv](https://arxiv.org/pdf/2403.10646.pdf)|
|AutoDev: Automated AI-Driven Development|Tufano et al|2024|[arXiv](https://arxiv.org/pdf/2403.08299.pdf)|
|Representation and Generation of Machine Learning Test Functions|Hassine et al|2024|[arXiv](Representation and Generation of Machine Learning Test Functions)|
|Leveraging pre-trained language models for code generation|Soliman et al|2024|[Springer](https://link.springer.com/article/10.1007/s40747-024-01373-8)|
|Programming Assistant for Exception Handling with CodeBERT|Cai et al.|2024|[ICSE](https://www.computer.org/csdl/proceedings-article/icse/2024/021700a878/1V5BkrGwfJu)|
|T5APR: Empowering Automated Program Repair Across Languages Through Checkpoint Ensemble|Gharibi et al.|2024|[arXiv](https://arxiv.org/pdf/2309.15742.pdf)|
|Generating Java Methods: An Empirical Assessment of Four AI-Based Code Assistants|Corso et al.|2024|[arXiv](https://arxiv.org/pdf/2402.08431.pdf)|
|IRCoder: Intermediate Representations Make Language Models Robust Multilingual Code Generators|Paul et al.|2024|[IRCoder](https://arxiv.org/pdf/2403.03894.pdf)|
|CodeUltraFeedback: An LLM-as-a-Judge Dataset for Aligning Large Language Models to Coding Preferences|Weyssow et al|2024|[arXiv](https://arxiv.org/pdf/2403.09032.pdf)|
|Conversational Assistants for Software Development: Integration, Traceability and Coordination|Contreras et al.|2024|[arXiv](https://miso.es/pubs/enase.pdf)|
|Improving Code Smell Detection Using Deep Stacked Autoencoder|Rehef et al.|2024|[preprints.org](https://www.preprints.org/manuscript/202403.1848/v1)|
|DeepCode AI Fix: Fixing Security Vulnerabilities with Large Language Models|Berabi et al|2024|[arXiv](https://arxiv.org/pdf/2402.13291.pdf)|
|RepairAgent: An Autonomous, LLM-Based Agent for Program Repair|Bouzenia et al|2024|[arXiv](https://arxiv.org/pdf/2403.17134.pdf)|
|Can It Edit? Evaluating the Ability of Large Language Models to Follow Code Editing Instructions|Cassano et al|2023|[arXiv](https://arxiv.org/pdf/2312.12450.pdf)|
|DeepSeek-Coder: When the Large Language Model Meets Programming -- The Rise of Code Intelligence|Guo et al|2024|[arXiv](https://arxiv.org/pdf/2401.14196.pdf)|
|AutoCodeRover: Autonomous Program Improvement|Zhang et al|2024|[arXiv](https://arxiv.org/pdf/2404.05427.pdf), [GitHub](https://github.com/nus-apr/auto-code-rover)|
|Trained Without My Consent: Detecting Code Inclusion In Language Models Trained on Code|Majdinasab et al.|2024|[GitHub](https://github.com/CommissarSilver/TraWiC), [arXiv](https://arxiv.org/pdf/2402.09299.pdf)|
|LongEmbed: Extending Embedding Models for Long Context Retrieval|Zhu et al|2024|[arXiv](https://arxiv.org/abs/2404.12096), [GitHub](https://github.com/dwzhu-pku/LongEmbed)|
|Out of the BLEU: How Should We Assess Quality of the Code Generation Models?|JetBrains|2023|[arXiv](https://arxiv.org/pdf/2208.03133.pdf)|
|NeuralSVG: An Implicit Representation for Text-to-Vector Generation|Polaczek et al|2025|[arXiv](https://arxiv.org/abs/2501.03992)|
|ModernBERT -Smarter, Better, Faster, Longer: A Modern Bidirectional Encoder for Fast, Memory Efficient, and Long Context Finetuning and Inference|Warner et al|2024|[arXiv](https://arxiv.org/abs/2412.13663)|
|CanIt Edit? Evaluating the Ability of Large Language Models to Follow Code Editing Instructions|Cassano et al|2024|[arXiv](https://arxiv.org/pdf/2312.12450), [GitHub](https://github.com/nuprl/CanItEdit)|
|Unsupervised Evaluation of Code LLMs with Round-Trip Correctness|Allamanis et al|2024|[arXiv](https://arxiv.org/abs/2402.08699)|
|Ansong Ni, Miltiadis Allamanis, Arman Cohan, Yinlin Deng, Kensen Shi, Charles Sutton, Pengcheng Yin|Ni et al|2024|[arXiv](https://arxiv.org/abs/2404.14662)|
|HumanEval Pro and MBPP Pro: Evaluating Large Language Models on Self-invoking Code Generation|Yu et al|2024|[arXiv](https://arxiv.org/abs/2412.21199)|
|Magicoder: Empowering Code Generation with OSS-Instruct|Wei et al|2024|[Proceedings](https://proceedings.mlr.press/v235/wei24h.html), [GitHub](https://github.com/ise-uiuc/magicoder)|
|SWT-Bench: Testing and Validating Real-World Bug-Fixes with Code Agents|Mündler et al.|2024|[ArXiv](https://arxiv.org/abs/2406.12952), [GitHub](https://github.com/logic-star-ai/swt-bench)|
|CodeSage: Code Representation at Scale|Zhang et al.|2024|[GitHub](https://github.com/amazon-science/CodeSage), [Website](https://code-representation-learning.github.io/), [arXiv](https://arxiv.org/abs/2402.01935)|
|Learning from Large Codebases|Veselin Raychev|2024|[ETHZ Zürich](https://files.sri.inf.ethz.ch/website/people/veselin/raychev_thesis.pdf)|
|AI-assisted Code Authoring at Scale: Fine-tuning, deploying, and mixed methods evaluation|Murali et al|2024|[arXiv](https://arxiv.org/pdf/2305.12050)|
|Automated Unit Test Improvement using Large Language Models at Meta|Alshahwan et al|2025|[arXiv](https://arxiv.org/pdf/2402.09171)|
|Competitive Programming with Large Reasoning Models|OpenAI|2025|[arXiv](https://arxiv.org/pdf/2502.06807v1)|
|EquiBench:Benchmarking Code Reasoning Capabilities of Large Language Models via Equivalence Checking|Wei et al|2025|[arXiv](https://arxiv.org/pdf/2502.12466)|
|GNN-Coder: Boosting Semantic Code Retrieval with Combined GNN and Transformer|Yet et al|2025|[arXiv](https://arxiv.org/pdf/2502.15202)|
|Code to Think, Think to Code: A Survey on Code-Enhanced Reasoning and Reasoning-Driven Code Intelligence in LLMs|Yang et al|2025|[arXiv](https://arxiv.org/pdf/2502.19411)|
|Large Language Models for Code Analysis: Do LLMs Really Do Their Job?|Fang et al|2024|[arXiv](https://arxiv.org/pdf/2310.12357)|
|Code Summarization: Do transformers really understand code?|Sontakke et al|2022|[arXiv](https://openreview.net/pdf?id=rI5ll2_-1Zc)|
|BaxBench: Can LLMs Generate Correct and Secure Backends?|Vero et al.|2025|[arXiv](https://arxiv.org/abs/2502.11844)|
|Testing the Effect of Code Documentation on Large Language Model Code Understanding|Macke et al|2024|[arXiv](https://arxiv.org/abs/2404.03114v1)|
|StarVector: Generating Scalable Vector Graphics Code From Images And Text|Rodriguez et al|2025|[arXiv](https://arxiv.org/abs/2312.11556), [Website](https://starvector.github.io/)
|Type-Constrained Code Generation with Language Models| Mündler et al|2025|[Openreview](https://openreview.net/pdf?id=LYVyioTwvF), [arXiv](https://arxiv.org/pdf/2504.09246)|
|InCoder: A Generative Model for Code Infilling and Synthesis|Fried et al.|2023|[arXiv](https://arxiv.org/pdf/2204.05999)|
|Syntactic and Semantic Control of Large Language Models via Sequential Monte Carlo|2025|[arXiv](https://arxiv.org/pdf/2504.13139)|